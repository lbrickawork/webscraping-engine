# -*- coding: utf-8 -*-
"""TP_Web_Scraping

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ti-3uDrL6Zkl2FRDR5rUsKEmSaxr5n8t

# TP de Web Scraping
Avec notation des erreurs rencontrées et leur correction
"""

# pip install requests
#
# pip install BeautifulSoup
#
# pip install pandas

#Importer les modules préalablement installés

# import requests
# from bs4 import BeautifulSoup
# import pandas as pd

#Url de la page
url="http://feeds.bbci.co.uk/news/world/europe/rss.xml"

"""**Erreur rencontrée** : oubli de l'installation préalable des paquets avant le lancement du script (point à ne pas oublier pour que les modules soient fonctionnels) cer le script s'exécute de haut en bas"""

#import le code l'url
reponse=requests.get(url)
soup=BeautifulSoup(reponse.text,"html.parser")


"""**Erreur rencontrée** : utilisation d'une page web qui ne disposait pas de la balise "item" ce qui renvoyait donc une erreur dans la suite du script qui nécessitait ces balises"""

items=soup.findAll('item')

item=items[0]

item.description.text
news_items=[]
for i in items:
    news_i={}
    news_i['title']=i.title.text
    news_i['description'] = i.title.text
    news_i['pubdate'] = i.title.text
    news_items.append(news_i)
news_items

#conversion de la liste en base de données
basedo=pd.DataFrame(news_items,columns=['title','description','pubdate'])

"""**Erreur rencontrée :**: une faute de syntaxe (absence de crochets) Python interprétait donc 'title' et le reste de la liste des items comme un autre élément."""

basedo.head(7)

#generer un fichier csv à partir du tableau
basedo.to_csv('TPweb_scraping.csv',index=False,encoding='utf-8')